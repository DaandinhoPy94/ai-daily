name: Scrape & Process News

on:
  schedule:
    # Run every 30 minutes
    - cron: '*/30 * * * *'
  workflow_dispatch:
    # Allow manual triggering

jobs:
  scrape-and-process:
    runs-on: ubuntu-latest

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'

      # Step 1: Scraper
      - name: Install scraper dependencies
        run: pip install -r scripts/scraper/requirements.txt

      - name: Run scraper
        env:
          SUPABASE_URL: ${{ secrets.SUPABASE_URL }}
          SUPABASE_SERVICE_KEY: ${{ secrets.SUPABASE_SERVICE_KEY }}
        run: python scripts/scraper/main.py

      # Step 2: AI Processor
      - name: Install processor dependencies
        run: pip install -r scripts/tekstverwerker/requirements.txt

      - name: Run AI processor
        env:
          SUPABASE_URL: ${{ secrets.SUPABASE_URL }}
          SUPABASE_SERVICE_KEY: ${{ secrets.SUPABASE_SERVICE_KEY }}
          OPENAI_API_KEY: ${{ secrets.OPENAI_API_KEY }}
        run: python scripts/tekstverwerker/processor.py

      # Step 3: Image Generator
      - name: Install image generator dependencies
        run: pip install -r scripts/afbeelding-generator/requirements.txt

      - name: Run image generator
        env:
          SUPABASE_URL: ${{ secrets.SUPABASE_URL }}
          SUPABASE_SERVICE_KEY: ${{ secrets.SUPABASE_SERVICE_KEY }}
          OPENAI_API_KEY: ${{ secrets.OPENAI_API_KEY }}
        run: python scripts/afbeelding-generator/image_generator.py
